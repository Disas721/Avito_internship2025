# Задача восстановления пробелов

Репозиторий содержит решение тестового задания по восстановлению пропусков в текстах на русском языке. Корпус получен из датасета Avito ML Cup 2025: использовались столбцы с названиями и описаниями объявлений, тексты преобразованы в символьный формат и очищены от лишних пробелов. Модель обучается определять, где в строке без пробелов необходимо восстановить разделители.

## Как устроено решение

- **Символьная модель** (`model_char_tagger.py`): компактный Transformer-энкодер (`TinyCharTransformer`) с синусоидальным позиционным кодированием и линейной головой. Токенизация выполняется классом `CharTokenizer`, который покрывает кириллицу, латиницу, цифры и основную пунктуацию.
- **Обучение** (`train_char_tagger.py`): сырой текст нормализуется функцией `make_pairs_from_line`, которая удаляет лишние пробелы и строит бинарные метки «ставить пробел после символа / нет». Для редких положительных примеров используется `BCEWithLogitsLoss` с повышенным весом положительного класса.
- **Правила постобработки** (`rules.py`): добавляет эвристики для пунктуации, процентов, смены алфавита и связки «цифра + буква», чтобы сгладить ошибочные вероятности модели.
- **Подбор порога** (`eval_f1.py`): превращает тексты из корпуса в пары «строка без пробелов + эталонные позиции», прогоняет модель по сетке трешхолдов и считает F1-score. Именно этот скрипт использовался для поиска оптимального порога на валидационном сете `avito_f1_val.parquet`.
- **Инференс** (`infer.py`): читает файл с колонками `id` и `text` (или «грязный» CSV без экранирования) и формирует `submission.csv` с колонкой `predicted_positions`. Порог берётся из шага подбора (`--thr`).
- **Ноутбук** (`avito_test_task.ipynb`): содержит последовательный запуск обучения, подбора порога и инференса теми же командами, что перечислены ниже.

## Подготовка данных

1. **Исходный корпус**: из Avito ML Cup 2025 выгружаются поля `title` и `description`. Все тексты приводятся к строкам, очищаются от лишних пробелов и пустых значений. Готовый датасет сохранён в `avito_clean.parquet`.
2. **Валидация порога**: подмножество строк сохранено в `avito_f1_val.parquet` — скрипт `eval_f1.py` использует его для подбора трешхолдов.
3. **Тестовый пример**: файл `task_data.txt` упрощённо повторяет формат задания — колонка `text_no_spaces` с текстами без пробелов. После инференса готовится `submission.csv` с восстановленными позициями пробелов.

## Установка окружения

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

Если используется GPU, убедитесь, что установлен совместимый билд PyTorch.

## Обучение модели

Базовая команда:

```bash
python3 train_char_tagger.py \
  --corpus avito_clean.parquet \
  --epochs 10 \
  --bs 256 \
  --lr 3e-4 \
  --max_len 256 \
  --save weights/char_tagger_gpu.pt
```

Ключевые параметры:
- `--corpus`: путь к parquet или txt. В parquet ожидается колонка `text`. Для txt — одна строка = один текст.
- `--max_len`: ограничение на длину последовательности (символы + BOS/EOS).
- `--bs`, `--lr`, `--epochs`: стандартные гиперпараметры обучения.
- `--save`: куда положить веса (создаются автоматически, если директория отсутствует).

Для обучения использовался GPU (в частности T4 на google colab).

## Подбор порога по F1

После обучения был подобран порог, чтобы перевести вероятности в бинарные решения:

```bash
python3 eval_f1.py \
  --corpus avito_f1_val.parquet \
  --column text \
  --weights weights/char_tagger_gpu.pt \
  --max_samples 20000 \
  --grid 0.70:0.90:0.01 \
  --save_json f1_grid.json
```

Скрипт напечатает таблицу `thr ↦ F1` и сохранит лучший порог. При использовании собственного корпуса обратите внимание на параметры `--min_len`, `--max_len` и `--column`.

## Инференс и подготовка сабмита

```bash
python3 infer.py \
  --input task_data.txt \
  --output submission.csv \
  --weights weights/char_tagger_gpu.pt \
  --thr 0.7
```

- Флаг `--use_pandas` включите, если входной CSV корректно экранирован (по умолчанию скрипт читает «рассыпанные» CSV без кавычек).
- Результат сохраняется с колонками `id`, `text`, `predicted_positions`, где позиции перечислены в квадратных скобках.

## Структура репозитория

- `model_char_tagger.py` — архитектура символьного Transformer и токенизатор.
- `train_char_tagger.py` — обучение модели, подготовка даталоадеров и сохранение весов.
- `rules.py` — эвристики.
- `eval_f1.py` — подбор порога по F1-score на валидационном корпусе.
- `infer.py` — inference-скрипт для подготовки ответа.
- `avito_test_task.ipynb` — пошаговый ноутбук с командами обучения/валидации/инференса.
- `weights/char_tagger_gpu.pt` — сохранённый чекпоинт модели.
- `avito_clean.parquet`, `avito_f1_val.parquet` — подготовленные наборы данных.
- `task_data.txt`, `submission.csv` — пример входа и готового вывода.
- `requirements.txt` — минимальные зависимости (PyTorch, pandas, numpy, pyarrow).
